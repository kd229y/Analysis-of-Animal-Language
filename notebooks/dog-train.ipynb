{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T08:25:52.590510Z",
     "iopub.status.busy": "2025-05-31T08:25:52.590227Z",
     "iopub.status.idle": "2025-05-31T08:34:52.362683Z",
     "shell.execute_reply": "2025-05-31T08:34:52.362134Z",
     "shell.execute_reply.started": "2025-05-31T08:25:52.590491Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2ForSequenceClassification, Wav2Vec2Processor\n",
    "import torch, torchaudio, os, random, numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader  \n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import gradio as gr\n",
    "from torch import nn\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "base_path = \"dog_sound_dataset\"  # 你的資料集路徑\n",
    "\n",
    "# 1. Processor + Model\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base\")\n",
    "model = (\n",
    "    Wav2Vec2ForSequenceClassification\n",
    "    .from_pretrained(\n",
    "        \"facebook/wav2vec2-base\",\n",
    "        num_labels=4,\n",
    "        problem_type=\"single_label_classification\"\n",
    "    )\n",
    "    .to(device)\n",
    ")\n",
    "# model.classifier.dropout = nn.Dropout(0.05)\n",
    "\n",
    "for p in model.wav2vec2.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "for layer in model.wav2vec2.encoder.layers[-2:]:\n",
    "    for p in layer.parameters():\n",
    "        p.requires_grad = True\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    lr=3e-5\n",
    ")\n",
    "\n",
    "# 2. Dataset & DataLoader (僅做 padding 相關修改)\n",
    "elementary = {\"Play\": 0, \"Defend\": 1, \"Beg\": 2, \"Fight\": 3}\n",
    "folders = [\"Play\", \"Defend\", \"Beg\", \"Fight\"]\n",
    "\n",
    "\n",
    "class DogSoundDataset(Dataset):\n",
    "    label_map = elementary\n",
    "\n",
    "    def __init__(self, base_path, folders, sr=16000, split=\"train\"):\n",
    "        self.items = []\n",
    "        self.sr = sr\n",
    "        for folder in folders:\n",
    "            subfolder = \"train_wav\" if split == \"train\" else \"val_wav\"\n",
    "            full_path = os.path.join(base_path, folder, subfolder)\n",
    "            if not os.path.exists(full_path):\n",
    "                print(f\"路徑不存在: {full_path}\")\n",
    "                continue\n",
    "\n",
    "            label = self.label_map[folder]\n",
    "            files = [f for f in os.listdir(full_path) if f.endswith(\".wav\")]\n",
    "            random.shuffle(files)\n",
    "            print(f\"{split} - {folder}: 找到 {len(files)} 個檔案\")\n",
    "\n",
    "            for fname in files:\n",
    "                self.items.append((os.path.join(full_path, fname), label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.items[idx]\n",
    "        wav, sr = torchaudio.load(path)\n",
    "        wav = torchaudio.functional.resample(wav, sr, self.sr) if sr != self.sr else wav\n",
    "        wav = wav.squeeze(0)\n",
    "        wav = wav / (wav.abs().max() + 1e-8)\n",
    "\n",
    "      \n",
    "        proc_output = processor(\n",
    "            wav.numpy(),\n",
    "            sampling_rate=self.sr,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,  \n",
    "            return_attention_mask=True  \n",
    "        )\n",
    "        input_values = proc_output.input_values.squeeze(0)       # (L,)\n",
    "        attention_mask = proc_output.attention_mask.squeeze(0)   # (L,)\n",
    "\n",
    "        return input_values, attention_mask, torch.tensor(label) \n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    all_vals, all_masks, all_labels = zip(*batch)\n",
    "    # 1) 對所有 input_values 做 pad，變成 (B, L_max)\n",
    "    vals = pad_sequence(all_vals, batch_first=True)       # (B, L_max)\n",
    "    # 2) 同理，對所有 attention_mask 也 pad 到 (B, L_max)，padding 的地方自動補 0\n",
    "    masks = pad_sequence(all_masks, batch_first=True)     # (B, L_max)\n",
    "\n",
    "    # 3) （原本的）per-sample normalization，可以保持\n",
    "    max_vals = vals.abs().amax(dim=1, keepdim=True)       # (B,1)\n",
    "    vals = vals / (max_vals + 1e-8)\n",
    "\n",
    "    labels = torch.stack(all_labels)                      # (B,)\n",
    "    return vals, masks, labels                            # 回傳三個：waveform, mask, label\n",
    "\n",
    "\n",
    "# 建立 train_ds / val_ds\n",
    "train_ds = DogSoundDataset(base_path, folders, split=\"train\")\n",
    "val_ds   = DogSoundDataset(base_path, folders, split=\"val\")\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=8,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "# 3. Training Loop\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    train_loss = train_corr = train_total = 0\n",
    "    for x, masks, y in train_loader:  \n",
    "        x, masks, y = x.to(device), masks.to(device), y.to(device)\n",
    "        \n",
    "        out = model(input_values=x, attention_mask=masks, labels=y)\n",
    "        loss, logits = out.loss, out.logits\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_corr += (logits.argmax(-1) == y).sum().item()\n",
    "        train_total += y.size(0)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = val_corr = val_total = 0\n",
    "    preds, trues = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, masks, y in val_loader:  \n",
    "            x, masks, y = x.to(device), masks.to(device), y.to(device)\n",
    "          \n",
    "            out = model(input_values=x, attention_mask=masks, labels=y)\n",
    "            val_loss += out.loss.item()\n",
    "            logits = out.logits\n",
    "            pred = logits.argmax(-1).cpu()\n",
    "            preds.extend(pred.tolist())\n",
    "            trues.extend(y.cpu().tolist())\n",
    "            val_corr += (pred == y.cpu()).sum().item()\n",
    "            val_total += y.size(0)\n",
    "\n",
    "    val_loss = val_loss / len(val_loader)\n",
    "    val_acc  = val_corr / val_total\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: \"\n",
    "          f\"Train Loss={train_loss/len(train_loader):.4f}, \"\n",
    "          f\"Train Acc={train_corr/train_total:.4f} | \"\n",
    "          f\"Val Loss={val_loss/len(val_loader):.4f}, \"\n",
    "          f\"Val Acc={val_corr/val_total:.4f}\")\n",
    "    cm = confusion_matrix(trues, preds, labels=[0,1,2,3])\n",
    "    disp = ConfusionMatrixDisplay(cm, display_labels=[\"Play\",\"Defend\",\"Beg\",\"Fight\"])\n",
    "    disp.plot()\n",
    "    plt.title(f\"Epoch {epoch+1} Confusion Matrix with human-based fine tuned pre-trained model and imbalanced data\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "torch.save(model.state_dict(), \"dog_classifier_final.pt\")\n",
    "\n",
    "\n",
    "def predict(path):\n",
    "    wav, sr = torchaudio.load(path)\n",
    "    if sr != 16000:\n",
    "        wav = torchaudio.transforms.Resample(sr,16000)(wav)\n",
    "    proc_output = processor(\n",
    "        wav.squeeze(0).numpy(),\n",
    "        sampling_rate=16000,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        return_attention_mask=True  \n",
    "    )\n",
    "    input_values = proc_output.input_values.to(device)\n",
    "    attention_mask = proc_output.attention_mask.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_values=input_values, attention_mask=attention_mask).logits\n",
    "    label = [\"Play\", \"Defend\", \"Beg\", \"Fight\"][logits.argmax(dim=1).item()]\n",
    "    return f\"Predicted: {label}\"\n",
    "\n",
    "interface = gr.Interface(\n",
    "    fn=predict,\n",
    "    inputs=gr.Audio(type=\"filepath\"),\n",
    "    outputs=\"text\",\n",
    "    title=\"你在狗叫什麼\",\n",
    "    description=\"狗狗叫聲：Play/Defend/Beg/Fight\"\n",
    ")\n",
    "interface.launch(share=True)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7532122,
     "sourceId": 11996517,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7546356,
     "sourceId": 11996882,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
